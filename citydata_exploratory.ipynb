{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Cleaning Data\n",
    "\n",
    "In the following code I will be performing both exploratory analysis and cleaning the data provided within three excel spreadsheets. These spreadsheets contain budget information for the City of Missoula and aligining Program Inventory information surrounding different programs that are funded by the City of Missoula. \n",
    "\n",
    "The data provided is messy and comes from both the financial software that is used, but also from a different software that collects survey responses. The data in the excel files is messy and unclean. This process will load the files into the environment, perform data cleaning functions to prepare the data for manipulation in Power Bi. In Power BI, I will create a dashboard that provides information about all of the different programs currently funded and provide granular breakdowns for financial and other important information therein. \n",
    "\n",
    "Once the data is cleaned I will conduct some exploratory analysis on the newly cleaned data to see how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Libraries\n",
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Text Cleaning\n",
    "import re\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Excel Handling\n",
    "import openpyxl\n",
    "\n",
    "# Additional Cleaning Utilities; each labeled below\n",
    "from tqdm import tqdm  # Adds progress bars to loops\n",
    "import chardet  # Detects encoding issues\n",
    "import janitor\n",
    "\n",
    "# Visualization\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the file paths \n",
    "data_path = \"data/\"\n",
    "\n",
    "## Load Files; only the first sheet in expenditure and program inventory, all of the sheets in revenue expense. \n",
    "revenue_expense = pd.read_excel(\n",
    "    os.path.join(data_path, \"FY24_Revenue_Expense_Data.xlsx\"), sheet_name=None, engine=\"openpyxl\")\n",
    "expenditure_status = pd.read_excel(\n",
    "    os.path.join(data_path, \"FY24_Expenditure_Status.xlsx\"), sheet_name=0, skiprows=6, engine=\"openpyxl\")\n",
    "program_inventory = pd.read_excel(\n",
    "    os.path.join(data_path, \"Program_Inventory_Internal_Data_Collection.xlsx\"), sheet_name=0, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display initial previews\n",
    "print(\"Revenue Expense Loaded:\", revenue_expense.keys())\n",
    "print(\"\\n Expenditure Status Preview:\")\n",
    "print(expenditure_status.head())\n",
    "\n",
    "print(\"\\n Program Inventory Preview:\")\n",
    "print(program_inventory.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Cleaning Functions\n",
    "\n",
    "def drop_unnamed_columns(df):\n",
    "    \"\"\"Drop columns with 'Unnamed' that are fully NaN.\"\"\"\n",
    "    return df.loc[:, ~df.columns.str.contains(\"^Unnamed\", na=False)]\n",
    "\n",
    "def clean_numeric_column(column):\n",
    "    \"\"\"Remove trailing '.0' and convert to clean string.\"\"\"\n",
    "    return column.astype(str).str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "def clean_identifiers(df):\n",
    "    \"\"\"Standardize Fund #, Activity Code, and Dept #.\"\"\"\n",
    "    if \"Fund #\" in df.columns:\n",
    "        df[\"Fund #\"] = df[\"Fund #\"].astype(str).str.split(\".\").str[0]\n",
    "\n",
    "    if \"Activity Code\" in df.columns:\n",
    "        df[\"Activity Code\"] = df[\"Activity Code\"].astype(str).str.split(\".\").str[0].str.zfill(6)\n",
    "\n",
    "    if \"Dept #\" in df.columns:\n",
    "        df[\"Dept #\"] = df[\"Dept #\"].astype(str).str.split(\".\").str[0].str.zfill(3)\n",
    "\n",
    "    return df\n",
    "\n",
    "def rename_multiline_headers(df):\n",
    "    \"\"\"Expand headers like 'Cost Recovery' to match multi-column layout.\"\"\"\n",
    "    column_mappings = {\n",
    "        \"Cost Recovery\": [\"Cost Recovery E58\", \"Cost Recovery P24\"],\n",
    "        \"Mandate\": [\"Mandate E41\", \"Mandate H41\", \"Mandate E43\"],\n",
    "        \"Service Level\": [\"Service Level E47\", \"Service Level H47\", \"Service Level E49\"],\n",
    "        \"Reliance & Interdependencies\": [\"Reliance E53\", \"Reliance E55\"],\n",
    "        \"Strategic Goal\": [\"Strategic Goal E64\", \"Strategic Goal E66\", \"Strategic Goal E68\", \"Strategic Goal E74\", \"Strategic Goal E80\"],\n",
    "        \"Trend (Demand)\": [\"Trend Demand E87\", \"Trend Demand E89\"],\n",
    "        \"Risk\": [\"Risk E93\", \"Risk E95\"]\n",
    "    }\n",
    "\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        if col in column_mappings:\n",
    "            new_columns.extend(column_mappings[col])\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "\n",
    "    df.columns = new_columns[:len(df.columns)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleaning Process for Expenditure Status\n",
    "# Drop empty unnamed columns\n",
    "df_expenditure_status = drop_unnamed_columns(expenditure_status).copy()\n",
    "\n",
    "# Rename first column\n",
    "df_expenditure_status.columns.values[0] = \"Account Number\"\n",
    "\n",
    "# Define split column names\n",
    "split_cols = [\"Fund #\", \"Dept #\", \"Activity Code\", \"Object Code\", \"Sub-object Code\"]\n",
    "\n",
    "# Split account numbers into structure\n",
    "split_data = df_expenditure_status[\"Account Number\"].astype(str).str.split(\".\", expand=True, n=4)\n",
    "split_data.columns = split_cols\n",
    "\n",
    "# Merge back into df_expenditure_status\n",
    "df_expenditure_status = pd.concat([df_expenditure_status, split_data], axis=1)\n",
    "\n",
    "# Convert types safely\n",
    "for col in split_cols:\n",
    "    df_expenditure_status[col] = pd.to_numeric(df_expenditure_status[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Forward fill Fund and Dept\n",
    "df_expenditure_status[[\"Fund #\", \"Dept #\"]] = df_expenditure_status[[\"Fund #\", \"Dept #\"]].ffill()\n",
    "\n",
    "# Drop rows missing Activity Code\n",
    "df_expenditure_status = df_expenditure_status.dropna(subset=[\"Activity Code\"])\n",
    "\n",
    "# Reset index\n",
    "df_expenditure_status = df_expenditure_status.reset_index(drop=True)\n",
    "\n",
    "# âœ… Checkpoint\n",
    "print(\"\\nðŸ§¼ Cleaned Expenditure Status Columns:\")\n",
    "print(df_expenditure_status.columns.tolist())\n",
    "print(df_expenditure_status.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Mapping\n",
    "# Extract from Expenditure\n",
    "dept_mapping = df_expenditure_status[[\"Dept #\"]].drop_duplicates().dropna()\n",
    "fund_mapping = df_expenditure_status[[\"Fund #\"]].drop_duplicates().dropna()\n",
    "\n",
    "# Assign human-readable department names (optional or manual override)\n",
    "dept_name_lookup = {\n",
    "    210: \"City Council\", 220: \"Mayor\", 230: \"Finance\", 240: \"Human Resources\",\n",
    "    250: \"Legal\", 260: \"Police\", 270: \"Fire\", 280: \"Public Works\",\n",
    "    290: \"Parks & Recreation\", 300: \"Planning & Development\", 310: \"Library\",\n",
    "    320: \"IT Services\", 330: \"Community Development\", 340: \"Housing Services\"\n",
    "}\n",
    "dept_mapping[\"Department\"] = dept_mapping[\"Dept #\"].map(dept_name_lookup).fillna(\"REDACTED\")\n",
    "df_expenditure_status = pd.merge(df_expenditure_status, dept_mapping, on=\"Dept #\", how=\"left\")\n",
    "\n",
    "# Optional: Display mappings\n",
    "print(\"\\nðŸ”Ž Extracted Department Mapping:\")\n",
    "print(dept_mapping.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expenditure_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean and Process Program Inventory\n",
    "# Rename Org to match Expenditure 'Dept #'\n",
    "df_program_inventory = program_inventory.rename(columns={\"Org\": \"Dept #\"})\n",
    "\n",
    "# Clean identifiers\n",
    "df_program_inventory = clean_identifiers(df_program_inventory)\n",
    "\n",
    "# Apply mappings\n",
    "df_program_inventory[\"Department\"] = df_program_inventory[\"Dept #\"].map(dept_name_lookup).fillna(\"REDACTED\")\n",
    "df_program_inventory[\"Fund Name\"] = df_program_inventory[\"Fund\"].map(fund_mapping.set_index(\"Fund #\").index.to_series())\n",
    "\n",
    "# Fix multi-line headers\n",
    "df_program_inventory = rename_multiline_headers(df_program_inventory)\n",
    "\n",
    "# Clean out empty columns\n",
    "df_program_inventory = drop_unnamed_columns(df_program_inventory)\n",
    "\n",
    "# Checkpoint\n",
    "print(\"\\nðŸ§¼ Cleaned Program Inventory Preview:\")\n",
    "print(df_program_inventory.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final cleaned datasets\n",
    "print(\"\\nâœ… Final Cleaned Expenditure Status (Sample):\")\n",
    "print(df_expenditure_status.head(10))\n",
    "\n",
    "print(\"\\nâœ… Final Cleaned Program Inventory (Sample):\")\n",
    "print(df_program_inventory.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## When using the comments in line, it allows you to easily reference them later by using help(function)\n",
    "## help(fix_multiline_headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
